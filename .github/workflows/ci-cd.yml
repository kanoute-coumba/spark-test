name: Spark ETL CI/CD

on:
  push:
    branches:
      - master

jobs:
  build:
    runs-on: ubuntu-latest

    env:
      KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
      KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Install Kaggle CLI
      run: pip install kaggle

    - name: Download dataset from Kaggle
      run: kaggle datasets download -d usdot/flight-delays -p ./datasets

    - name: Unzip dataset
      run: unzip ./datasets/flight-delays.zip -d ./datasets

    - name: Set dataset path environment variable
      run: echo "DATASET_PATH=./datasets/flights.csv" >> $GITHUB_ENV

    - name: Cache Python dependencies
      uses: actions/cache@v2
      with:
        path: |
          ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Set dataset path environment variable
      run: echo "DATASET_PATH=${{ env.DATASET_PATH }}" >> $GITHUB_ENV

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.12

    - name: Install dependencies
      run: |
        python3 -m pip install --upgrade pip
        pip install pyspark

    - name: Run the script
      run: spark-submit make_etl.py
      working-directory: ${{ github.workspace }}

    - name: copy file via ssh key
      uses: appleboy/scp-action@v0.1.7
      with:
        host: ${{ secrets.HOST }}
        username: ${{ secrets.USERNAME }}
        port: ${{ secrets.PORT }}
        key: ${{ secrets.KEY }}
        source: "make_etl.py"
        target: /home/kanouch

